# NeuroInformatics Project 1
William Z. Repo
The final model run for this part of the project is through run_model2.ipynb. It can be run on the A100 Google Colab.

There are many model architectures I have tried, with varying degrees of success.
- My initial start was to look at the SRCNN paper, which is implemented in the **m3_model.py**, following this paper: https://arxiv.org/pdf/1501.00092. While it worked, it yielded poor results
- I wanted to try to use a SOAT model, (something that use transformers, attentions, MAMBA, etc.), and tried to use the mdoel architecture in *SuperFormer: Volumetric Transformer Architectures for MRI Super-Resolution*: https://arxiv.org/abs/2406.03359v1. The **m5_model.py** was pulled from their github. Unfortunately was not successful in running it.
- I given these past two attempts, I looked for a tutorial, which landed me at this git repo https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Super-Resolution/tree/master?tab=readme-ov-file, which is a tutorial on implementing Resnet. I was able to run, but I had to fudge with its architecture, which again degraded performance. Their model architecture is stored in **m4_model.py**.
- I used Claude for help on developing a model, which can be seen in **m6_model.py** and in run_model2.ipynb as *UNet3DUpsampler* while *SRResNet* is from **m4_model.py** is from a tutorial mentioned previously. As it turns out, the image quality generated by Claude was much better and cleaner. Here is the conversation: https://claude.ai/share/1e539a3d-53ca-4db0-882d-da3cc89afad8


# Operations
The main ways I test, cleaned, and investigated datasets was through datasets.py while training and comparing image results was done through main.py.
```bash
dataset.py gen1
dataset.py gen2
# Different formats to create Dataset from torch. gen1 is for 2d images and gen2 is for 3d images.

dataset.py view 1
dataset.py view 2
# View 1 is to view the raw files as images. View 2 is to see the images after data loaders
dataset.py info
# Get metadata

dataset.py super
dataset.py resnet
# to see images the respective models will get
```

```bash
main.py resnet
# To see the untrained result of the resnet model (possible to manually change model in the file as well)
main.py resnet train
# To see the train result of the resnet model (possible to manually change model in the file as well)
```
